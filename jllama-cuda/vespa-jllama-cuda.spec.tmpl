# Copyright Vespa.ai. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.

# Disable build id note requirement for now
%undefine _missing_build_ids_terminate_build

# Force special prefix for Vespa
%define _prefix /opt/vespa-deps

%global debug_package %{nil}

# Don't provide shared library or pkgconfig
%global __provides_exclude ^(lib.*\\.so\\.[0-9]*\\(\\)\\(64bit\\)|(cmake|pkgconfig)\\(.*)$

%global __requires_exclude ^lib.*lama\.so\\.[0-9.]*\\([A-Z._0-9]*\\)\\(64bit\\)$

# Version
%define ver_major _TMPL_VER_MAJOR
%define ver_minor _TMPL_VER_MINOR
%define ver_patch _TMPL_VER_PATCH
%define ver_release _TMPL_VER_RELEASE

%global _vespa_openblas_version 0.3.27

Summary:        Native part of Java Bindings for llama.cpp using CUDA
Name:           vespa-jllama-cuda
Version:        %{ver_major}.%{ver_minor}.%{ver_patch}
Release:        %{ver_release}%{?dist}
License:        MIT
URL:            https://github.com/kherud/
Source0:        https://github.com/kherud/java-llama.cpp/archive/refs/tags/v%{version}.tar.gz

%if 0%{?el8} || 0%{?el9} || 0%{?fedora}
BuildRequires: java-17-openjdk-devel
BuildRequires: maven
%endif

%if 0%{?el8}%{?el9}
BuildRequires: vespa-toolset-12-meta
%define _devtoolset_enable /opt/rh/gcc-toolset-12/enable
BuildRequires: cuda-libraries-devel-12-2
BuildRequires: cuda-compiler-12-2
BuildRequires: cuda-cudart-devel-12-2
BuildRequires: cuda-command-line-tools-12-2
%endif

BuildRequires: vespa-openblas-devel >= %{_vespa_openblas_version}
Requires: vespa-openblas >= %{_vespa_openblas_version}

BuildRequires: vespa-cmake
BuildRequires: make
BuildRequires: git

Requires:       cuda-cudart-12-2
Requires:       libcublas-12-2

%global _vespa_3rdparty_deps_packaging_notice \
See https://github.com/vespa-engine/vespa-3rdparty-deps for details \
about packaging.

%description
%{_vespa_3rdparty_deps_packaging_notice}

%prep
%setup -q -n java-llama.cpp-%{version}

%build
%if 0%{?_devtoolset_enable:1}
source %{_devtoolset_enable} || true
%endif

PATH=%{_prefix}/bin:/usr/local/cuda-12.2/bin:$PATH
mvn compile
mkdir build
cd build
cmake  \
    -DCMAKE_INSTALL_RPATH=\$ORIGIN \
    -DCMAKE_BUILD_WITH_INSTALL_RPATH=true \
    -DLLAMA_NATIVE=OFF \
    -DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS \
    -DLLAMA_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES="60;70;75" \
    ..
cmake --build . --config Release

%install

mkdir -p %{buildroot}%{_libdir}/cuda
cp -p src/main/resources/de/kherud/llama/Linux/*/lib*.so %{buildroot}%{_libdir}/cuda

%files
%license LICENSE.md
%{_libdir}

%changelog

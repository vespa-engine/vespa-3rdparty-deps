# Copyright Vespa.ai. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.

# Disable build id note requirement for now
%undefine _missing_build_ids_terminate_build

# Force special prefix for Vespa
%define _prefix /opt/vespa-deps

%global debug_package %{nil}

# Don't provide shared library or pkgconfig
%global __provides_exclude ^(lib.*\\.so[0-9.]*\\(\\)\\(64bit\\)|(cmake|pkgconfig)\\(.*)$

%global __requires_exclude ^lib(jllama|llama|ggml)\.so[0-9.]*\\([A-Z._0-9]*\\)\\(64bit\\)$

# Version
%define ver_major _TMPL_VER_MAJOR
%define ver_minor _TMPL_VER_MINOR
%define ver_patch _TMPL_VER_PATCH
%define ver_release _TMPL_VER_RELEASE

Summary:        Native part of Java Bindings for llama.cpp using CUDA
Name:           vespa-jllama-cuda
Version:        %{ver_major}.%{ver_minor}.%{ver_patch}
Release:        %{ver_release}%{?dist}
License:        MIT
URL:            https://github.com/kherud/
Source0:        https://github.com/kherud/java-llama.cpp/archive/refs/tags/v%{version}.tar.gz

%if 0%{?el8} || 0%{?el9} || 0%{?fedora}
BuildRequires: java-17-openjdk-devel
BuildRequires: maven
%endif

%if 0%{?el8}%{?el9}
BuildRequires: vespa-toolset-12-meta
BuildRequires: vespa-ccache
BuildRequires: vespa-cmake
%define _devtoolset_enable /opt/rh/gcc-toolset-12/enable
%else
BuildRequires: cmake
%endif

BuildRequires: cuda-libraries-devel-12-2
BuildRequires: cuda-compiler-12-2
BuildRequires: cuda-cudart-devel-12-2
BuildRequires: cuda-command-line-tools-12-2

BuildRequires: make
BuildRequires: git

Requires:       cuda-cudart-12-2
Requires:       libcublas-12-2

%global _vespa_3rdparty_deps_packaging_notice \
See https://github.com/vespa-engine/vespa-3rdparty-deps for details \
about packaging.

%description
%{_vespa_3rdparty_deps_packaging_notice}

%prep
%setup -q -n java-llama.cpp-%{version}

%build
%if 0%{?_devtoolset_enable:1}
source %{_devtoolset_enable} || true
%endif

PATH=%{_prefix}/bin:/usr/local/cuda-12.2/bin:$PATH
mvn compile
mkdir build

cmake -B build \
    -DCMAKE_INSTALL_RPATH=\$ORIGIN \
    -DCMAKE_BUILD_WITH_INSTALL_RPATH=true \
    -DCMAKE_BUILD_TYPE=RelWithDebInfo \
    -DCMAKE_C_FLAGS_RELWITHDEBINFO="-g -O3 -DNDEBUG" \
    -DCMAKE_CXX_FLAGS_RELWITHDEBINFO="-g -O3 -DNDEBUG" \
    -DGGML_METAL=OFF \
    -DGGML_OPENMP=OFF \
    -DGGML_NATIVE=OFF \
    -DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES="60;70;75" \
    -DLLAMA_NATIVE=OFF

VERBOSE=1 cmake --build build --config RelWithDebInfo -j 4

%install

mkdir -p %{buildroot}%{_libdir}/cuda
cp -p src/main/resources_linux_cuda/de/kherud/llama/Linux/*/lib*.so %{buildroot}%{_libdir}/cuda

%files
%license LICENSE.md
%{_libdir}

%changelog
